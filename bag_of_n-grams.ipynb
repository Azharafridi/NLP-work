{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30c3688e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'thor': 5, 'mathodawala': 4, 'is': 1, 'looking': 3, 'for': 0, 'job': 2}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vector = CountVectorizer(ngram_range = (1,1))\n",
    "vector.fit([\"Thor Mathodawala is looking for a job\"])\n",
    "vector.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e020e5ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'thor': 9,\n",
       " 'mathodawala': 7,\n",
       " 'is': 2,\n",
       " 'looking': 5,\n",
       " 'for': 0,\n",
       " 'job': 4,\n",
       " 'thor mathodawala': 10,\n",
       " 'mathodawala is': 8,\n",
       " 'is looking': 3,\n",
       " 'looking for': 6,\n",
       " 'for job': 1}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = CountVectorizer(ngram_range = (1,2))\n",
    "vector.fit([\"Thor Mathodawala is looking for a job\"])\n",
    "vector.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9098e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'thor': 12,\n",
       " 'mathodawala': 9,\n",
       " 'is': 2,\n",
       " 'looking': 6,\n",
       " 'for': 0,\n",
       " 'job': 5,\n",
       " 'thor mathodawala': 13,\n",
       " 'mathodawala is': 10,\n",
       " 'is looking': 3,\n",
       " 'looking for': 7,\n",
       " 'for job': 1,\n",
       " 'thor mathodawala is': 14,\n",
       " 'mathodawala is looking': 11,\n",
       " 'is looking for': 4,\n",
       " 'looking for job': 8}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = CountVectorizer(ngram_range = (1,3))\n",
    "vector.fit([\"Thor Mathodawala is looking for a job\"])\n",
    "vector.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97778e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"Thor ate pizza\",\n",
    "    \"Loki is tall\",\n",
    "    \"Loki is eating pizza\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed524a6f",
   "metadata": {},
   "source": [
    "### how text convert into a vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffbfd5d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thor eat pizza'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# load english language model and create nlp object from it\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def preprocess(text):\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    filtered_tokens = []\n",
    "    for token in doc:\n",
    "        if token.is_stop or token.is_punct:\n",
    "            continue\n",
    "        filtered_tokens.append(token.lemma_)\n",
    "    return \" \".join(filtered_tokens)\n",
    "\n",
    "preprocess(\"Thor ate pizza\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90f283f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thor eat pizza', 'Loki tall', 'Loki eat pizza']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the whole corpus is preprocessed and the stop words are removed\n",
    "\n",
    "\n",
    "corpus_preproces = [preprocess(text) for text in corpus]\n",
    "corpus_preproces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad672bfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'thor': 7,\n",
       " 'eat': 0,\n",
       " 'pizza': 5,\n",
       " 'thor eat': 8,\n",
       " 'eat pizza': 1,\n",
       " 'loki': 2,\n",
       " 'tall': 6,\n",
       " 'loki tall': 4,\n",
       " 'loki eat': 3}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = CountVectorizer(ngram_range = (1,2))\n",
    "vector.fit(corpus_preproces)\n",
    "vector.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b52eab9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0, 0, 1, 0, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we convert the bag of words into a vector which is nothing but array of integers\n",
    "# becuase machine understand numbers not words\n",
    "\n",
    "vector.transform([\"Thor eat pizza\"]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4dfff8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0, 0, 1, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.transform([\"Hulk eat pizza\"]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64135cf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db7f7e2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>headline</th>\n",
       "      <th>category</th>\n",
       "      <th>short_description</th>\n",
       "      <th>authors</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.huffpost.com/entry/covid-boosters-...</td>\n",
       "      <td>Over 4 Million Americans Roll Up Sleeves For O...</td>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>Health experts said it is too early to predict...</td>\n",
       "      <td>Carla K. Johnson, AP</td>\n",
       "      <td>2022-09-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.huffpost.com/entry/american-airlin...</td>\n",
       "      <td>American Airlines Flyer Charged, Banned For Li...</td>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>He was subdued by passengers and crew when he ...</td>\n",
       "      <td>Mary Papenfuss</td>\n",
       "      <td>2022-09-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.huffpost.com/entry/funniest-tweets...</td>\n",
       "      <td>23 Of The Funniest Tweets About Cats And Dogs ...</td>\n",
       "      <td>COMEDY</td>\n",
       "      <td>\"Until you have a dog you don't understand wha...</td>\n",
       "      <td>Elyse Wanshel</td>\n",
       "      <td>2022-09-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.huffpost.com/entry/funniest-parent...</td>\n",
       "      <td>The Funniest Tweets From Parents This Week (Se...</td>\n",
       "      <td>PARENTING</td>\n",
       "      <td>\"Accidentally put grown-up toothpaste on my to...</td>\n",
       "      <td>Caroline Bologna</td>\n",
       "      <td>2022-09-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.huffpost.com/entry/amy-cooper-lose...</td>\n",
       "      <td>Woman Who Called Cops On Black Bird-Watcher Lo...</td>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>Amy Cooper accused investment firm Franklin Te...</td>\n",
       "      <td>Nina Golgowski</td>\n",
       "      <td>2022-09-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                link  \\\n",
       "0  https://www.huffpost.com/entry/covid-boosters-...   \n",
       "1  https://www.huffpost.com/entry/american-airlin...   \n",
       "2  https://www.huffpost.com/entry/funniest-tweets...   \n",
       "3  https://www.huffpost.com/entry/funniest-parent...   \n",
       "4  https://www.huffpost.com/entry/amy-cooper-lose...   \n",
       "\n",
       "                                            headline   category  \\\n",
       "0  Over 4 Million Americans Roll Up Sleeves For O...  U.S. NEWS   \n",
       "1  American Airlines Flyer Charged, Banned For Li...  U.S. NEWS   \n",
       "2  23 Of The Funniest Tweets About Cats And Dogs ...     COMEDY   \n",
       "3  The Funniest Tweets From Parents This Week (Se...  PARENTING   \n",
       "4  Woman Who Called Cops On Black Bird-Watcher Lo...  U.S. NEWS   \n",
       "\n",
       "                                   short_description               authors  \\\n",
       "0  Health experts said it is too early to predict...  Carla K. Johnson, AP   \n",
       "1  He was subdued by passengers and crew when he ...        Mary Papenfuss   \n",
       "2  \"Until you have a dog you don't understand wha...         Elyse Wanshel   \n",
       "3  \"Accidentally put grown-up toothpaste on my to...      Caroline Bologna   \n",
       "4  Amy Cooper accused investment firm Franklin Te...        Nina Golgowski   \n",
       "\n",
       "        date  \n",
       "0 2022-09-23  \n",
       "1 2022-09-23  \n",
       "2 2022-09-23  \n",
       "3 2022-09-23  \n",
       "4 2022-09-22  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json(\"News_Category_Dataset_v3.json\", lines = True)\n",
    "df.shape\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1847501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "POLITICS          35602\n",
       "WELLNESS          17945\n",
       "ENTERTAINMENT     17362\n",
       "TRAVEL             9900\n",
       "STYLE & BEAUTY     9814\n",
       "PARENTING          8791\n",
       "HEALTHY LIVING     6694\n",
       "QUEER VOICES       6347\n",
       "FOOD & DRINK       6340\n",
       "BUSINESS           5992\n",
       "COMEDY             5400\n",
       "SPORTS             5077\n",
       "BLACK VOICES       4583\n",
       "HOME & LIVING      4320\n",
       "PARENTS            3955\n",
       "THE WORLDPOST      3664\n",
       "WEDDINGS           3653\n",
       "WOMEN              3572\n",
       "CRIME              3562\n",
       "IMPACT             3484\n",
       "DIVORCE            3426\n",
       "WORLD NEWS         3299\n",
       "MEDIA              2944\n",
       "WEIRD NEWS         2777\n",
       "GREEN              2622\n",
       "WORLDPOST          2579\n",
       "RELIGION           2577\n",
       "STYLE              2254\n",
       "SCIENCE            2206\n",
       "TECH               2104\n",
       "TASTE              2096\n",
       "MONEY              1756\n",
       "ARTS               1509\n",
       "ENVIRONMENT        1444\n",
       "FIFTY              1401\n",
       "GOOD NEWS          1398\n",
       "U.S. NEWS          1377\n",
       "ARTS & CULTURE     1339\n",
       "COLLEGE            1144\n",
       "LATINO VOICES      1130\n",
       "CULTURE & ARTS     1074\n",
       "EDUCATION          1014\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6c623e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sample = 1014\n",
    "df_POLITICS = df[df.category =='POLITICS'].sample(min_sample, random_state = 2022)\n",
    "df_WELLNESS = df[df.category =='WELLNESS'].sample(min_sample, random_state = 2022)\n",
    "df_ENTERTAINMENT = df[df.category =='ENTERTAINMENT'].sample(min_sample, random_state = 2022)\n",
    "df_TRAVEL = df[df.category =='TRAVEL'].sample(min_sample, random_state = 2022)\n",
    "df_STYLEBEAUTY = df[df.category =='STYLE & BEAUTY'].sample(min_sample, random_state = 2022)\n",
    "df_PAHEALTHY_LIVING = df[df.category =='HEALTHY LIVING'].sample(min_sample, random_state = 2022)\n",
    "df_QUEER_VOICES = df[df.category =='QUEER VOICES'].sample(min_sample, random_state = 2022)\n",
    "df_FOODDRINK = df[df.category =='FOOD & DRINK'].sample(min_sample, random_state = 2022)\n",
    "df_BUSINESS = df[df.category =='BUSINESS'].sample(min_sample, random_state = 2022)\n",
    "df_COMEDY = df[df.category =='COMEDY'].sample(min_sample, random_state = 2022)\n",
    "df_SPORTS = df[df.category =='SPORTS'].sample(min_sample, random_state = 2022)\n",
    "df_BLACK_VOICES = df[df.category =='BLACK VOICES'].sample(min_sample, random_state = 2022)\n",
    "df_HOME_LIVING = df[df.category =='HOME & LIVING'].sample(min_sample, random_state = 2022)\n",
    "df_PARENTS = df[df.category =='PARENTS'].sample(min_sample, random_state = 2022)\n",
    "df_THE_WORLDPOST = df[df.category =='THE WORLDPOST'].sample(min_sample, random_state = 2022)\n",
    "df_WEDDINGS = df[df.category =='WEDDINGS'].sample(min_sample, random_state = 2022)\n",
    "df_WOMEN = df[df.category =='WOMEN'].sample(min_sample, random_state = 2022)\n",
    "df_CRIME = df[df.category =='CRIME'].sample(min_sample, random_state = 2022)\n",
    "df_IMPACT = df[df.category =='IMPACT'].sample(min_sample, random_state = 2022)\n",
    "df_DIVORCE = df[df.category =='DIVORCE'].sample(min_sample, random_state = 2022)\n",
    "df_WORLD_NEWS = df[df.category =='WORLD NEWS'].sample(min_sample, random_state = 2022)\n",
    "df_MEDIA = df[df.category =='MEDIA'].sample(min_sample, random_state = 2022)\n",
    "df_WEIRD_NEWS = df[df.category =='WEIRD NEWS'].sample(min_sample, random_state = 2022)\n",
    "df_GREEN = df[df.category =='GREEN'].sample(min_sample, random_state = 2022)\n",
    "df_WORLDPOST = df[df.category =='WORLDPOST'].sample(min_sample, random_state = 2022)\n",
    "df_RELIGION = df[df.category =='RELIGION'].sample(min_sample, random_state = 2022)\n",
    "df_STYLE = df[df.category =='STYLE'].sample(min_sample, random_state = 2022)\n",
    "df_SCIENCE = df[df.category =='SCIENCE'].sample(min_sample, random_state = 2022)\n",
    "df_TECH = df[df.category =='TECH'].sample(min_sample, random_state = 2022)\n",
    "df_TASTE = df[df.category =='TASTE'].sample(min_sample, random_state = 2022)\n",
    "df_MONEY = df[df.category =='MONEY'].sample(min_sample, random_state = 2022)\n",
    "df_ARTS = df[df.category =='ARTS'].sample(min_sample, random_state = 2022)\n",
    "df_ENVIRONMENT = df[df.category =='ENVIRONMENT'].sample(min_sample, random_state = 2022)\n",
    "df_FIFTY = df[df.category =='FIFTY'].sample(min_sample, random_state = 2022)\n",
    "df_GOOD_NEWS = df[df.category =='GOOD NEWS'].sample(min_sample, random_state = 2022)\n",
    "df_U_S_NEWS = df[df.category =='U.S. NEWS'].sample(min_sample, random_state = 2022)\n",
    "df_ARTS_CULTURE = df[df.category =='ARTS & CULTURE'].sample(min_sample, random_state = 2022)\n",
    "df_COLLEGE = df[df.category =='COLLEGE'].sample(min_sample, random_state = 2022)\n",
    "df_LATINO_VOICES = df[df.category =='LATINO VOICES'].sample(min_sample, random_state = 2022)\n",
    "df_CULTURE_ARTS = df[df.category =='CULTURE & ARTS'].sample(min_sample, random_state = 2022)\n",
    "df_education = df[df.category =='EDUCATION'].sample(min_sample, random_state = 2022)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efaa5b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_STYLE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "811b9862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STYLE             2028\n",
       "POLITICS          1014\n",
       "WELLNESS          1014\n",
       "WEIRD NEWS        1014\n",
       "GREEN             1014\n",
       "WORLDPOST         1014\n",
       "RELIGION          1014\n",
       "TECH              1014\n",
       "TASTE             1014\n",
       "MONEY             1014\n",
       "ARTS              1014\n",
       "ENVIRONMENT       1014\n",
       "FIFTY             1014\n",
       "GOOD NEWS         1014\n",
       "U.S. NEWS         1014\n",
       "ARTS & CULTURE    1014\n",
       "COLLEGE           1014\n",
       "LATINO VOICES     1014\n",
       "CULTURE & ARTS    1014\n",
       "MEDIA             1014\n",
       "WORLD NEWS        1014\n",
       "DIVORCE           1014\n",
       "COMEDY            1014\n",
       "ENTERTAINMENT     1014\n",
       "TRAVEL            1014\n",
       "STYLE & BEAUTY    1014\n",
       "HEALTHY LIVING    1014\n",
       "QUEER VOICES      1014\n",
       "FOOD & DRINK      1014\n",
       "BUSINESS          1014\n",
       "SPORTS            1014\n",
       "IMPACT            1014\n",
       "BLACK VOICES      1014\n",
       "HOME & LIVING     1014\n",
       "PARENTS           1014\n",
       "THE WORLDPOST     1014\n",
       "WEDDINGS          1014\n",
       "WOMEN             1014\n",
       "CRIME             1014\n",
       "EDUCATION         1014\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_balanced = pd.concat([df_POLITICS,df_WELLNESS,df_ENTERTAINMENT,df_TRAVEL,df_STYLEBEAUTY,df_PAHEALTHY_LIVING,df_QUEER_VOICES,df_FOODDRINK,\n",
    "                         df_BUSINESS,df_COMEDY,df_SPORTS,df_BLACK_VOICES,df_HOME_LIVING,df_PARENTS,df_THE_WORLDPOST,df_WEDDINGS,df_WOMEN,\n",
    "                         df_CRIME,df_IMPACT,df_DIVORCE,df_WORLD_NEWS,df_MEDIA,df_WEIRD_NEWS,df_GREEN,df_WORLDPOST,df_RELIGION,df_STYLE,\n",
    "                         df_STYLE,df_TECH,df_TASTE,df_MONEY,df_ARTS,df_ENVIRONMENT,df_FIFTY,df_GOOD_NEWS,df_U_S_NEWS,df_ARTS_CULTURE,\n",
    "                         df_COLLEGE,df_LATINO_VOICES,df_CULTURE_ARTS,df_education], axis = 0)\n",
    "df_balanced.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2b5dada9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced['category_num'] = df_balanced.category.map({\n",
    "    'STYLE ': 0,\n",
    "    'POLITICS':1,\n",
    "    'WELLNESS': 2,\n",
    "    'WEIRD NEWS':3,\n",
    "    'GREEN' : 4,\n",
    "    'WORLDPOST' :5,\n",
    "    'RELIGION': 6,\n",
    "    'TECH' : 7,\n",
    "    'TASTE' :8,\n",
    "    'MONEY' : 9,\n",
    "    'ARTS' : 10,\n",
    "    'ENVIRONMENT': 11,\n",
    "    'FIFTY' :12,\n",
    "    'GOOD NEWS':13,\n",
    "    'U.S. NEWS' : 14,\n",
    "    'ARTS & CULTURE': 15,\n",
    "    'MEDIA' : 16,\n",
    "    'WORLD NEWS' : 17,\n",
    "    'DIVORCE' : 18,\n",
    "    'COMEDY' : 19,\n",
    "    'ENTERTAINMENT': 20,\n",
    "    'TRAVEL' : 21,\n",
    "    'STYLE & BEAUTY' : 22,\n",
    "    'HEALTHY LIVING' :23,\n",
    "    'QUEER VOICES' : 24,\n",
    "    'FOOD & DRINK' :25,\n",
    "    'BUSINESS' : 26,\n",
    "    'SPORTS' : 27,\n",
    "    'IMPACT' : 28,\n",
    "    'BLACK VOICES' :29,\n",
    "    'HOME & LIVING' :30,\n",
    "    'PARENTS' : 31,\n",
    "    'THE WORLDPOST' : 32,\n",
    "    'WEDDINGS' : 33,\n",
    "    'WOMEN' : 34,\n",
    "    'CRIME' : 35,\n",
    "    'EDUCATION' :36\n",
    "    \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cc4b8baf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>headline</th>\n",
       "      <th>category</th>\n",
       "      <th>short_description</th>\n",
       "      <th>authors</th>\n",
       "      <th>date</th>\n",
       "      <th>category_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16014</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/trump-hea...</td>\n",
       "      <td>The Coverage Of Trump’s Big Dumb Body Is Fat W...</td>\n",
       "      <td>POLITICS</td>\n",
       "      <td>The president, it evidently needs to be said, ...</td>\n",
       "      <td>Travis Waldron</td>\n",
       "      <td>2018-01-18</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25545</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/dreamers-...</td>\n",
       "      <td>Dreamers Are People, Not Political Footballs</td>\n",
       "      <td>POLITICS</td>\n",
       "      <td>People should not be reduced to pawns used by ...</td>\n",
       "      <td>Center for Community Change Action, Contributo...</td>\n",
       "      <td>2017-09-09</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51291</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/democrats...</td>\n",
       "      <td>Democrats Must Elect Bernie Sanders Senate Min...</td>\n",
       "      <td>POLITICS</td>\n",
       "      <td>The Senate will meet this Wednesday to elect i...</td>\n",
       "      <td>Linda Milazzo, ContributorParticipatory journa...</td>\n",
       "      <td>2016-11-13</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41123</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/jcc-lette...</td>\n",
       "      <td>Jewish Leaders Frustrated By Lack Of Progress ...</td>\n",
       "      <td>POLITICS</td>\n",
       "      <td>In a letter to Attorney General Jeff Sessions,...</td>\n",
       "      <td>Matt Ferner</td>\n",
       "      <td>2017-03-08</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10450</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/donald-tr...</td>\n",
       "      <td>Donald Trump Roasted For Painfully Awkward Att...</td>\n",
       "      <td>POLITICS</td>\n",
       "      <td>Well, that didn't seem to go as planned.</td>\n",
       "      <td>Rebecca Shapiro</td>\n",
       "      <td>2018-04-24</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    link  \\\n",
       "16014  https://www.huffingtonpost.com/entry/trump-hea...   \n",
       "25545  https://www.huffingtonpost.com/entry/dreamers-...   \n",
       "51291  https://www.huffingtonpost.com/entry/democrats...   \n",
       "41123  https://www.huffingtonpost.com/entry/jcc-lette...   \n",
       "10450  https://www.huffingtonpost.com/entry/donald-tr...   \n",
       "\n",
       "                                                headline  category  \\\n",
       "16014  The Coverage Of Trump’s Big Dumb Body Is Fat W...  POLITICS   \n",
       "25545       Dreamers Are People, Not Political Footballs  POLITICS   \n",
       "51291  Democrats Must Elect Bernie Sanders Senate Min...  POLITICS   \n",
       "41123  Jewish Leaders Frustrated By Lack Of Progress ...  POLITICS   \n",
       "10450  Donald Trump Roasted For Painfully Awkward Att...  POLITICS   \n",
       "\n",
       "                                       short_description  \\\n",
       "16014  The president, it evidently needs to be said, ...   \n",
       "25545  People should not be reduced to pawns used by ...   \n",
       "51291  The Senate will meet this Wednesday to elect i...   \n",
       "41123  In a letter to Attorney General Jeff Sessions,...   \n",
       "10450           Well, that didn't seem to go as planned.   \n",
       "\n",
       "                                                 authors       date  \\\n",
       "16014                                     Travis Waldron 2018-01-18   \n",
       "25545  Center for Community Change Action, Contributo... 2017-09-09   \n",
       "51291  Linda Milazzo, ContributorParticipatory journa... 2016-11-13   \n",
       "41123                                        Matt Ferner 2017-03-08   \n",
       "10450                                    Rebecca Shapiro 2018-04-24   \n",
       "\n",
       "       category_num  \n",
       "16014           1.0  \n",
       "25545           1.0  \n",
       "51291           1.0  \n",
       "41123           1.0  \n",
       "10450           1.0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "caecf571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5070"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced['category_num'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b36e3ada",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input y contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m----> 3\u001b[0m X_train, X_test,  y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdf_balanced\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlink\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdf_balanced\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcategory_num\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2022\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstratify\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdf_balanced\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcategory_num\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2583\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2579\u001b[0m         CVClass \u001b[38;5;241m=\u001b[39m ShuffleSplit\n\u001b[0;32m   2581\u001b[0m     cv \u001b[38;5;241m=\u001b[39m CVClass(test_size\u001b[38;5;241m=\u001b[39mn_test, train_size\u001b[38;5;241m=\u001b[39mn_train, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m-> 2583\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstratify\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   2585\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m   2586\u001b[0m     chain\u001b[38;5;241m.\u001b[39mfrom_iterable(\n\u001b[0;32m   2587\u001b[0m         (_safe_indexing(a, train), _safe_indexing(a, test)) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[0;32m   2588\u001b[0m     )\n\u001b[0;32m   2589\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2160\u001b[0m, in \u001b[0;36mStratifiedShuffleSplit.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   2126\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, groups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   2127\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Generate indices to split data into training and test set.\u001b[39;00m\n\u001b[0;32m   2128\u001b[0m \n\u001b[0;32m   2129\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2158\u001b[0m \u001b[38;5;124;03m    to an integer.\u001b[39;00m\n\u001b[0;32m   2159\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2160\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   2161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39msplit(X, y, groups)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:921\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    915\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    916\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    917\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    918\u001b[0m         )\n\u001b[0;32m    920\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 921\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m            \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m            \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    929\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:161\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    147\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    148\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    149\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m     )\n\u001b[1;32m--> 161\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input y contains NaN."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test,  y_train, y_test = train_test_split(\n",
    "            df_balanced.link,\n",
    "            df_balanced.category_num,\n",
    "            test_size = 0.2,\n",
    "            random_state = 2022,\n",
    "            stratify = df_balanced.category_num)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b0afdcc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mX_train\u001b[49m\u001b[38;5;241m.\u001b[39mshape()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "X_train.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388eae97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9ff882",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19273a06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb25cdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
